{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784) (50000,) (10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.io import read_image\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "DATA_PATH = Path(\"data\") / \"mnist\"\n",
    "MODEL_PATH = Path(\"model\") / \"mnist\"\n",
    "\n",
    "DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "with gzip.open((DATA_PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "            ((x_train, y_train), (x_valid, y_valid),\n",
    "             _) = pickle.load(f, encoding=\"latin-1\")\n",
    "print(x_train.shape, y_train.shape, x_valid.shape, y_valid.shape)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class MnistDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.reshape(torch.from_numpy(x), (len(y), 1, 28, 28))\n",
    "        self.y = torch.from_numpy(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # N(batch), Channels ,Height, Width\n",
    "        return self.x[i], self.y[i]\n",
    "\n",
    "train_mnist_dataset = MnistDataset(x_train, y_train)\n",
    "test_mnist_dataset = MnistDataset(x_valid, y_valid)\n",
    "\n",
    "BATCH_SIZE = 50\n",
    "train_dataloader = DataLoader(\n",
    "    train_mnist_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(\n",
    "    test_mnist_dataset, batch_size=len(x_valid), shuffle=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# x_batch, y_batch = next(iter(train_dataloader))\n",
    "# plt.figure(num='Training set samples',figsize=(8,8))\n",
    "# for i in range(4):\n",
    "#     plt.subplot(2,2,i+1)     \n",
    "#     plt.title(y_batch[i])   \n",
    "#     plt.imshow(x_batch[i][0], plt.cm.gray)      \n",
    "#     plt.axis('off')     \n",
    "# plt.show()   #显示窗口\n",
    "\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6,\n",
    "                               kernel_size=5, stride=1, padding=0)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
    "        self.fc1 = nn.Linear(in_features=4*4*16, out_features=120, bias=True)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=84, bias=True)\n",
    "        self.fc3 = nn.Linear(in_features=84, out_features=10, bias=True)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 4*4*16)  # should be 5*5*16 if it's 32*32 image\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = self.softmax(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# define Lenet-5 model\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def accuracy_on_test(model, onGPU=False):\n",
    "    with torch.no_grad():\n",
    "        x_batch, y_batch = next(iter(test_dataloader))\n",
    "        if onGPU:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        y_output = model(x_batch)\n",
    "        y_predict = torch.max(y_output, 1).indices\n",
    "        correct_nums = (y_predict == y_batch).sum().item()\n",
    "        return correct_nums, len(y_batch), correct_nums/len(y_batch) * 100\n",
    "\n",
    "def predict(model, onGPU=False):\n",
    "    with torch.no_grad():\n",
    "        x_batch, y_batch = next(iter(test_dataloader))\n",
    "        if onGPU:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        x_batch = x_batch[:4]\n",
    "        y_output = model(x_batch)\n",
    "        y_predict = torch.max(y_output, 1).indices\n",
    "        plt.figure(num='Training set samples',figsize=(8,8))\n",
    "        for i in range(4):\n",
    "            plt.subplot(2,2,i+1)     \n",
    "            plt.title(y_predict[i])   \n",
    "            plt.imshow(x_batch[i][0], plt.cm.gray)      \n",
    "            plt.axis('off')     \n",
    "        plt.show()   #显示窗口\n",
    "    \n",
    "def train(model, optimizer, onGPU=False):\n",
    "    start = time.time()\n",
    "    for epoch in range(EPOCHS):\n",
    "        epoch_loss = 0.0\n",
    "        for x_batch, y_batch in iter(train_dataloader):\n",
    "            if onGPU:\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            y_output = model(x_batch)\n",
    "\n",
    "            # compute loss\n",
    "            loss = criterion(y_output, y_batch)\n",
    "\n",
    "            # compute gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # optimize\n",
    "            optimizer.step()\n",
    "\n",
    "            # add loss\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        correct, total, accuracy = accuracy_on_test(model, onGPU)\n",
    "        print('Epoch: %d, loss: %.3f, accuracy on test set:  %d/%d = %.3f' %\n",
    "              (epoch + 1, epoch_loss, correct, total, accuracy))\n",
    "\n",
    "    end = time.time()-start\n",
    "    if onGPU:\n",
    "        torch.save(model.state_dict(), MODEL_PATH / \"lenet_5_gpu_model.pt\")\n",
    "        print('Finished GPU Training,takes %d seconds\\n' % (end))\n",
    "    else:\n",
    "        torch.save(model.state_dict(), MODEL_PATH / \"lenet_5_cpu_model.pt\")\n",
    "        print('Finished CPU Training,takes %d seconds\\n' % (end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 2302.278, accuracy on test set:  1064/10000 = 10.640\n",
      "Epoch: 2, loss: 2301.306, accuracy on test set:  1064/10000 = 10.640\n",
      "Epoch: 3, loss: 2296.806, accuracy on test set:  2092/10000 = 20.920\n",
      "Epoch: 4, loss: 1902.331, accuracy on test set:  8078/10000 = 80.780\n",
      "Epoch: 5, loss: 1650.295, accuracy on test set:  8421/10000 = 84.210\n",
      "Epoch: 6, loss: 1624.205, accuracy on test set:  8527/10000 = 85.270\n",
      "Epoch: 7, loss: 1611.330, accuracy on test set:  8634/10000 = 86.340\n",
      "Epoch: 8, loss: 1603.038, accuracy on test set:  8659/10000 = 86.590\n",
      "Epoch: 9, loss: 1596.566, accuracy on test set:  8740/10000 = 87.400\n",
      "Epoch: 10, loss: 1591.487, accuracy on test set:  8700/10000 = 87.000\n",
      "Epoch: 11, loss: 1587.644, accuracy on test set:  8796/10000 = 87.960\n",
      "Epoch: 12, loss: 1584.333, accuracy on test set:  8837/10000 = 88.370\n",
      "Epoch: 13, loss: 1581.236, accuracy on test set:  8846/10000 = 88.460\n",
      "Epoch: 14, loss: 1579.208, accuracy on test set:  8852/10000 = 88.520\n",
      "Epoch: 15, loss: 1577.347, accuracy on test set:  8863/10000 = 88.630\n",
      "Epoch: 16, loss: 1575.398, accuracy on test set:  8866/10000 = 88.660\n",
      "Epoch: 17, loss: 1573.929, accuracy on test set:  8857/10000 = 88.570\n",
      "Epoch: 18, loss: 1572.244, accuracy on test set:  8873/10000 = 88.730\n",
      "Epoch: 19, loss: 1571.119, accuracy on test set:  8881/10000 = 88.810\n",
      "Epoch: 20, loss: 1569.722, accuracy on test set:  8886/10000 = 88.860\n",
      "Epoch: 21, loss: 1569.417, accuracy on test set:  8907/10000 = 89.070\n",
      "Epoch: 22, loss: 1568.478, accuracy on test set:  8913/10000 = 89.130\n",
      "Epoch: 23, loss: 1567.369, accuracy on test set:  8904/10000 = 89.040\n",
      "Epoch: 24, loss: 1566.671, accuracy on test set:  8919/10000 = 89.190\n",
      "Epoch: 25, loss: 1565.939, accuracy on test set:  8924/10000 = 89.240\n",
      "Epoch: 26, loss: 1565.144, accuracy on test set:  8910/10000 = 89.100\n",
      "Epoch: 27, loss: 1564.642, accuracy on test set:  8918/10000 = 89.180\n",
      "Epoch: 28, loss: 1564.074, accuracy on test set:  8925/10000 = 89.250\n",
      "Epoch: 29, loss: 1563.780, accuracy on test set:  8897/10000 = 88.970\n",
      "Epoch: 30, loss: 1562.935, accuracy on test set:  8929/10000 = 89.290\n",
      "Finished CPU Training,takes 217 seconds\n",
      "\n",
      "Epoch: 1, loss: 2302.276, accuracy on test set:  1285/10000 = 12.850\n",
      "Epoch: 2, loss: 2301.602, accuracy on test set:  1135/10000 = 11.350\n",
      "Epoch: 3, loss: 2299.826, accuracy on test set:  2272/10000 = 22.720\n",
      "Epoch: 4, loss: 2186.141, accuracy on test set:  7091/10000 = 70.910\n",
      "Epoch: 5, loss: 1687.926, accuracy on test set:  8243/10000 = 82.430\n",
      "Epoch: 6, loss: 1628.157, accuracy on test set:  8567/10000 = 85.670\n",
      "Epoch: 7, loss: 1611.350, accuracy on test set:  8606/10000 = 86.060\n",
      "Epoch: 8, loss: 1601.418, accuracy on test set:  8730/10000 = 87.300\n",
      "Epoch: 9, loss: 1593.891, accuracy on test set:  8743/10000 = 87.430\n",
      "Epoch: 10, loss: 1589.268, accuracy on test set:  8780/10000 = 87.800\n",
      "Epoch: 11, loss: 1585.566, accuracy on test set:  8818/10000 = 88.180\n",
      "Epoch: 12, loss: 1582.940, accuracy on test set:  8815/10000 = 88.150\n",
      "Epoch: 13, loss: 1580.767, accuracy on test set:  8841/10000 = 88.410\n",
      "Epoch: 14, loss: 1578.329, accuracy on test set:  8853/10000 = 88.530\n",
      "Epoch: 15, loss: 1576.637, accuracy on test set:  8848/10000 = 88.480\n",
      "Epoch: 16, loss: 1575.359, accuracy on test set:  8871/10000 = 88.710\n",
      "Epoch: 17, loss: 1573.901, accuracy on test set:  8880/10000 = 88.800\n",
      "Epoch: 18, loss: 1572.908, accuracy on test set:  8889/10000 = 88.890\n",
      "Epoch: 19, loss: 1571.944, accuracy on test set:  8877/10000 = 88.770\n",
      "Epoch: 20, loss: 1570.671, accuracy on test set:  8898/10000 = 88.980\n",
      "Epoch: 21, loss: 1569.862, accuracy on test set:  8907/10000 = 89.070\n",
      "Epoch: 22, loss: 1569.050, accuracy on test set:  8908/10000 = 89.080\n",
      "Epoch: 23, loss: 1568.118, accuracy on test set:  8928/10000 = 89.280\n",
      "Epoch: 24, loss: 1567.414, accuracy on test set:  8923/10000 = 89.230\n",
      "Epoch: 25, loss: 1566.404, accuracy on test set:  8914/10000 = 89.140\n",
      "Epoch: 26, loss: 1565.609, accuracy on test set:  8910/10000 = 89.100\n",
      "Epoch: 27, loss: 1564.892, accuracy on test set:  8941/10000 = 89.410\n",
      "Epoch: 28, loss: 1564.061, accuracy on test set:  8927/10000 = 89.270\n",
      "Epoch: 29, loss: 1563.313, accuracy on test set:  8940/10000 = 89.400\n",
      "Epoch: 30, loss: 1562.694, accuracy on test set:  8956/10000 = 89.560\n",
      "Finished GPU Training,takes 138 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define Lenet-5 model\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# start training\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 0.03\n",
    "criterion = nn.CrossEntropyLoss()  # used in classification problem\n",
    "\n",
    "# using CPU\n",
    "model = LeNet5()\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "train(model, optimizer, False)\n",
    "\n",
    "# using GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "gpu_model = LeNet5()\n",
    "gpu_model = gpu_model.to(device)\n",
    "gpu_optimizer = optim.SGD(gpu_model.parameters(), lr=LEARNING_RATE)\n",
    "train(gpu_model, gpu_optimizer, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# inference\n",
    "model = LeNet5()\n",
    "model.load_state_dict(torch.load(MODEL_PATH / \"lenet_5_cpu_model.pt\"))\n",
    "model.eval()\n",
    "predict(model, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}