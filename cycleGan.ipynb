{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "%matplotlib inline\n",
    "\n",
    "# CycleGan implementation reference: https://towardsdatascience.com/overview-of-cyclegan-architecture-and-training-afee31612a2f\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv_block = nn.Sequential(\n",
    "            # [N, 256, 64, 64] -> [N, 256, 64, 64]\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256,\n",
    "                      kernel_size=3, stride=1),\n",
    "            nn.InstanceNorm2d(num_features=256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # [N, 256, 64, 64] -> [N, 256, 64, 64]\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256,\n",
    "                      kernel_size=3, stride=1),\n",
    "            nn.InstanceNorm2d(num_features=256),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input has size [N, C, H, W] = [N, 256, 64, 64]\n",
    "        return x + self.conv_block(x)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, n_residuals):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # [Batch, C, H, W]\n",
    "        modules = []\n",
    "\n",
    "        # [Batch, 3, 256, 256] -> [Batch, 64, 256, 256]\n",
    "        modules += [nn.ReflectionPad2d(3),\n",
    "                    nn.Conv2d(in_channels=3, out_channels=64,\n",
    "                              kernel_size=7, stride=1),\n",
    "                    nn.InstanceNorm2d(num_features=64),\n",
    "                    nn.ReLU(inplace=True)]\n",
    "\n",
    "        # [Batch, 64, 256, 256] -> [Batch, 128, 128, 128]\n",
    "        modules += [nn.Conv2d(in_channels=64, out_channels=128,\n",
    "                              kernel_size=3, stride=2, padding=1),\n",
    "                    nn.InstanceNorm2d(num_features=128),\n",
    "                    nn.ReLU(inplace=True)]\n",
    "\n",
    "        # [Batch, 128, 128, 128] -> [Batch, 256, 64, 64]\n",
    "        modules += [nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=1),\n",
    "                    nn.InstanceNorm2d(num_features=256),\n",
    "                    nn.ReLU(inplace=True)]\n",
    "\n",
    "        for _ in range(n_residuals):\n",
    "            modules += [ResidualBlock()]\n",
    "\n",
    "        # [Batch, 256, 64, 64] -> [Batch, 128, 128, 128]\n",
    "        modules += [nn.ConvTranspose2d(in_channels=256, out_channels=128,\n",
    "                                       kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                    nn.InstanceNorm2d(num_features=128),\n",
    "                    nn.ReLU(inplace=True)]\n",
    "\n",
    "        # [Batch, 128, 128, 128] -> [Batch, 64, 256, 256]\n",
    "        modules += [nn.ConvTranspose2d(in_channels=128, out_channels=64,\n",
    "                                       kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                    nn.InstanceNorm2d(num_features=64),\n",
    "                    nn.ReLU(inplace=True)]\n",
    "\n",
    "        # [Batch, 64, 256, 256]-> [Batch, 3, 256, 256]\n",
    "        modules += [nn.ReflectionPad2d(3),\n",
    "                    nn.Conv2d(in_channels=64, out_channels=3,\n",
    "                              kernel_size=7, stride=1),\n",
    "                    nn.Tanh()\n",
    "                    ]\n",
    "\n",
    "        self.stack = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input image: [Batch, 3, 256, 256] -> output image: [Batch, 3, 256, 256]\n",
    "        return self.stack(input)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.stack = nn.Sequential(\n",
    "\n",
    "            #  image input  [Batch, 3, 256, 256]  ->  [Batch, 64, 128, 128]\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=4,\n",
    "                      stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            #  [Batch, 64, 128, 128] -> [Batch, 128, 64, 64]\n",
    "            nn.Conv2d(in_channels=64, out_channels=128,\n",
    "                      kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(num_features=128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            #  [Batch, 128, 64, 64] -> [Batch, 256, 32, 32]\n",
    "            nn.Conv2d(in_channels=128, out_channels=256,\n",
    "                      kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(num_features=256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # [Batch, 256, 32, 32] -> [Batch, 512, 31, 31]\n",
    "            nn.Conv2d(in_channels=256, out_channels=512,\n",
    "                      kernel_size=4, stride=1, padding=1),\n",
    "            nn.InstanceNorm2d(num_features=512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # [Batch, 512, 31, 31] -> [Batch, 1, 30, 30]\n",
    "            # Each value of the output tensor 30x30 holds the classification result for a 70x70 area of the input image.\n",
    "            nn.Conv2d(in_channels=512, out_channels=1, kernel_size=4,\n",
    "                      stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        #  image input  [Batch, 3, 256, 256] -> [Batch, 1, 30, 30]\n",
    "        x = self.stack(input)\n",
    "        avg_filter_size = x.size()[2:]  # [30,30]\n",
    "        x = F.avg_pool2d(x, kernel_size=avg_filter_size)\n",
    "        x = x.view(-1)  # [Batch,]\n",
    "        return x\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "\n",
    "n_epochs = 50\n",
    "batch_size = 1\n",
    "dataroot = 'data/maps/'\n",
    "lr = 0.0002\n",
    "image_size = 256\n",
    "\n",
    "device = torch.device(\"cuda:0\" if (\n",
    "    torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "# Create the Discriminator\n",
    "netD_A = Discriminator().to(device)\n",
    "netD_B = Discriminator().to(device)\n",
    "\n",
    "# Create the generator\n",
    "n_residuals = 9\n",
    "netG_AB = Generator(n_residuals).to(device)\n",
    "netG_BA = Generator(n_residuals).to(device)\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "netD_A.apply(weights_init)\n",
    "netD_B.apply(weights_init)\n",
    "netG_AB.apply(weights_init)\n",
    "netG_BA.apply(weights_init)\n",
    "\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, dataroot, transform, mode):\n",
    "        self.filesA = glob.glob('%s%s*A\\*' % (dataroot, mode))\n",
    "        self.filesB = glob.glob('%s%s*B\\*' % (dataroot, mode))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.filesA), len(self.filesB))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        a = Image.open(self.filesA[idx % len(self.filesA)]).convert('RGB')\n",
    "        # avoid fixed paired images\n",
    "        b = Image.open(self.filesB[random.randint(\n",
    "            0, len(self.filesB)-1)]).convert('RGB')\n",
    "        return {'A': self.transform(a), 'B': self.transform(b)}\n",
    "\n",
    "\n",
    "# A-horse 1067  B-zebra 1334\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(int(image_size * 1.12)),\n",
    "    transforms.RandomCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_dataset = ImageDataset('data\\\\maps\\\\', transform,  'train')\n",
    "test_dataset = ImageDataset('data\\\\maps\\\\', transform,  'test')\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "optimizerG = torch.optim.Adam(\n",
    "    itertools.chain(netG_AB.parameters(), netG_BA.parameters()), lr=lr, betas=(0.5, 0.999)\n",
    ")\n",
    "optimizerD_A = optim.Adam(netD_A.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizerD_B = optim.Adam(netD_B.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "criterion_identity = nn.L1Loss()\n",
    "criterion_cycle = nn.L1Loss()\n",
    "criterion_gan = nn.MSELoss()\n",
    "\n",
    "real_labels = torch.full((batch_size,), 1, dtype=torch.float,\n",
    "                         device=device, requires_grad=False)\n",
    "fake_labels = torch.full((batch_size,), 0, dtype=torch.float,\n",
    "                         device=device, requires_grad=False)\n",
    "\n",
    "\n",
    "def plot_AB_pair(pair):\n",
    "    # {A:[1,3,256,256],B:[1,3,256,256]}\n",
    "    img_list = [pair['A'].squeeze(), pair['B'].squeeze()]\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(np.transpose(vutils.make_grid(\n",
    "        img_list, padding=2, normalize=True), (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "real_batch = next(iter(dataloader))\n",
    "plot_AB_pair(real_batch)\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    # For each batch in the dataloader\n",
    "    for i, batch in enumerate(dataloader):\n",
    "\n",
    "        # train Generator\n",
    "        optimizerG.zero_grad()\n",
    "        real_A = batch['A'].to(device)  # torch.Size([Batch, 3, 256, 256]))\n",
    "        real_B = batch['B'].to(device)  # torch.Size([Batch, 3, 256, 256]))\n",
    "\n",
    "        # cycle loss\n",
    "        fake_B = netG_AB(real_A)\n",
    "        fake_A = netG_BA(real_B)\n",
    "        rec_A = netG_BA(fake_B)\n",
    "        rec_B = netG_AB(fake_A)\n",
    "\n",
    "        cycle_loss_A = criterion_cycle(rec_A, real_A)\n",
    "        cycle_loss_B = criterion_cycle(rec_B, real_B)\n",
    "\n",
    "        # identity loss\n",
    "        identity_loss_A = criterion_identity(netG_BA(real_A), real_A)\n",
    "        identity_loss_B = criterion_identity(netG_AB(real_B), real_B)\n",
    "\n",
    "        # gan loss\n",
    "        gan_loss_A = criterion_gan(netD_A(fake_A), real_labels)\n",
    "        gan_loss_B = criterion_gan(netD_B(fake_B), real_labels)\n",
    "        lossG = (cycle_loss_A+cycle_loss_B)*10.0 + (identity_loss_A +\n",
    "                                                    identity_loss_B)*5.0+(gan_loss_A+gan_loss_B)\n",
    "        lossG.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        # train Discriminator A\n",
    "        optimizerD_A.zero_grad()\n",
    "        lossD_A = (criterion_gan(netD_A(real_A), real_labels) +\n",
    "                   criterion_gan(netD_A(fake_A.detach()), fake_labels))*0.5\n",
    "        lossD_A.backward()\n",
    "        optimizerD_A.step()\n",
    "\n",
    "        # train Discriminator B\n",
    "        optimizerD_B.zero_grad()\n",
    "        lossD_B = (criterion_gan(netD_B(real_B), real_labels) +\n",
    "                   criterion_gan(netD_B(fake_B.detach()), fake_labels))*0.5\n",
    "        lossD_B.backward()\n",
    "        optimizerD_B.step()\n",
    "\n",
    "        if i % 200 == 0:\n",
    "#             print('Epoch: %d/%d, batch: [%d/%d], lossG: %.2f, lossD_A: %.2f, lossD_B: %.2f' %\n",
    "#                   (epoch, n_epochs, i, len(dataloader), lossG, lossD_A, lossD_B))\n",
    "            with torch.no_grad():\n",
    "                a = test_dataset[10]['A'].unsqueeze(0).to(device)\n",
    "                fake_b = netG_AB(a)\n",
    "                plot_AB_pair({'A': a.to('cpu'), 'B': fake_b.to('cpu')})\n",
    "\n",
    "    # save after every 50 epoch\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        path = \"model/cycleGan/maps/\"\n",
    "        torch.save(netG_AB.state_dict(), path + \"netG_AB_%d.pt\" % (epoch+1))\n",
    "        torch.save(netG_BA.state_dict(), path + \"netG_BA_%d.pt\" % (epoch+1))\n",
    "        torch.save(netD_A.state_dict(), path + \"netD_A_%d.pt\" % (epoch+1))\n",
    "        torch.save(netD_B.state_dict(), path + \"netD_B_%d.pt\" % (epoch+1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}